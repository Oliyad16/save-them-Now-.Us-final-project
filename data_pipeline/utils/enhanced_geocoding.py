"""
Enhanced geocoding service with automatic processing for new entries.
Supports multiple providers and batch processing with rate limiting.
"""

import asyncio
import aiohttp
import json
import time
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
import sqlite3
import hashlib

from .logger import get_logger

logger = get_logger("enhanced_geocoding")

class EnhancedGeocodingService:
    """Enhanced geocoding service with multiple providers and automatic processing."""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.cache_file = Path(config.get('cache_file', 'geocache.json'))
        self.db_path = Path(config.get('database_path', 'database/app.db'))
        
        # Load cache
        self.cache = self.load_cache()
        
        # Geocoding providers with fallbacks
        self.providers = [
            {
                'name': 'nominatim',
                'base_url': 'https://nominatim.openstreetmap.org/search',
                'rate_limit': 1.0,  # seconds between requests
                'timeout': 10,
                'headers': {
                    'User-Agent': 'SaveThemNow.Jesus/1.0 (missing-persons-awareness)'
                }
            },
            {
                'name': 'photon',
                'base_url': 'https://photon.komoot.io/api',
                'rate_limit': 0.5,
                'timeout': 8,
                'headers': {}
            },
            {
                'name': 'geocodify',
                'base_url': 'https://api.geocodify.com/v2/geocode',
                'rate_limit': 2.0,
                'timeout': 10,
                'headers': {}
            }
        ]\n        \n        # US bounds for validation\n        self.us_bounds = {\n            'min_lat': 24.0,\n            'max_lat': 49.0,\n            'min_lon': -125.0,\n            'max_lon': -66.0\n        }\n        \n        # Statistics tracking\n        self.stats = {\n            'cache_hits': 0,\n            'cache_misses': 0,\n            'successful_geocodes': 0,\n            'failed_geocodes': 0,\n            'provider_usage': {},\n            'processing_time': 0\n        }\n    \n    def load_cache(self) -> Dict[str, Dict[str, float]]:\n        \"\"\"Load geocoding cache from file.\"\"\"\n        try:\n            if self.cache_file.exists():\n                with open(self.cache_file, 'r', encoding='utf-8') as f:\n                    cache_data = json.load(f)\n                    logger.logger.info(f\"Loaded geocoding cache with {len(cache_data)} entries\")\n                    return cache_data\n        except Exception as e:\n            logger.logger.error(f\"Failed to load geocache: {e}\")\n        \n        return {}\n    \n    def save_cache(self):\n        \"\"\"Save geocoding cache to file.\"\"\"\n        try:\n            with open(self.cache_file, 'w', encoding='utf-8') as f:\n                json.dump(self.cache, f, indent=2)\n            logger.logger.info(f\"Saved geocoding cache with {len(self.cache)} entries\")\n        except Exception as e:\n            logger.logger.error(f\"Failed to save geocache: {e}\")\n    \n    def get_cache_key(self, city: str, state: str, country: str = 'USA') -> str:\n        \"\"\"Generate cache key for location.\"\"\"\n        return f\"{city.lower().strip()},{state.lower().strip()},{country.lower().strip()}\"\n    \n    def is_in_us_bounds(self, lat: float, lon: float) -> bool:\n        \"\"\"Check if coordinates are within US bounds.\"\"\"\n        return (\n            self.us_bounds['min_lat'] <= lat <= self.us_bounds['max_lat'] and\n            self.us_bounds['min_lon'] <= lon <= self.us_bounds['max_lon']\n        )\n    \n    async def geocode_with_provider(self, session: aiohttp.ClientSession, \n                                  provider: Dict[str, Any], \n                                  city: str, state: str, \n                                  country: str = 'USA') -> Optional[Dict[str, Any]]:\n        \"\"\"Geocode using a specific provider.\"\"\"\n        try:\n            query = f\"{city}, {state}, {country}\"\n            \n            if provider['name'] == 'nominatim':\n                params = {\n                    'q': query,\n                    'format': 'json',\n                    'limit': 1,\n                    'countrycodes': 'us'\n                }\n                url = provider['base_url']\n            elif provider['name'] == 'photon':\n                params = {\n                    'q': query,\n                    'limit': 1\n                }\n                url = provider['base_url']\n            else:\n                # Generic provider format\n                params = {'q': query, 'limit': 1}\n                url = provider['base_url']\n            \n            async with session.get(\n                url, \n                params=params, \n                headers=provider['headers'],\n                timeout=aiohttp.ClientTimeout(total=provider['timeout'])\n            ) as response:\n                \n                if response.status == 200:\n                    data = await response.json()\n                    \n                    if data and len(data) > 0:\n                        result = data[0]\n                        lat = float(result.get('lat', 0))\n                        lon = float(result.get('lon', 0))\n                        \n                        # Validate coordinates\n                        if self.is_in_us_bounds(lat, lon):\n                            self.stats['provider_usage'][provider['name']] = \\\n                                self.stats['provider_usage'].get(provider['name'], 0) + 1\n                            \n                            return {\n                                'lat': lat,\n                                'lon': lon,\n                                'provider': provider['name'],\n                                'quality': 'high' if 'display_name' in result else 'medium'\n                            }\n            \n            # Rate limiting\n            await asyncio.sleep(provider['rate_limit'])\n            \n        except Exception as e:\n            logger.logger.debug(f\"Geocoding failed with {provider['name']}: {e}\")\n        \n        return None\n    \n    async def geocode_location(self, city: str, state: str, country: str = 'USA') -> Optional[Dict[str, Any]]:\n        \"\"\"Geocode a location using multiple providers with fallbacks.\"\"\"\n        if not city or not state:\n            return None\n        \n        cache_key = self.get_cache_key(city, state, country)\n        \n        # Check cache first\n        if cache_key in self.cache:\n            self.stats['cache_hits'] += 1\n            cached = self.cache[cache_key]\n            return {\n                'lat': cached['lat'],\n                'lon': cached['lon'],\n                'provider': cached.get('provider', 'cache'),\n                'quality': cached.get('quality', 'cached')\n            }\n        \n        self.stats['cache_misses'] += 1\n        \n        # Try providers in order\n        async with aiohttp.ClientSession() as session:\n            for provider in self.providers:\n                result = await self.geocode_with_provider(session, provider, city, state, country)\n                if result:\n                    # Cache the result\n                    self.cache[cache_key] = {\n                        'lat': result['lat'],\n                        'lon': result['lon'],\n                        'provider': result['provider'],\n                        'quality': result['quality'],\n                        'timestamp': datetime.now().isoformat()\n                    }\n                    \n                    self.stats['successful_geocodes'] += 1\n                    return result\n        \n        self.stats['failed_geocodes'] += 1\n        logger.logger.warning(f\"Failed to geocode: {city}, {state}\")\n        return None\n    \n    async def batch_geocode(self, locations: List[Dict[str, str]], \n                          progress_callback: Optional[callable] = None,\n                          batch_size: int = 10) -> List[Optional[Dict[str, Any]]]:\n        \"\"\"Batch geocode multiple locations.\"\"\"\n        logger.logger.info(f\"Starting batch geocoding of {len(locations)} locations\")\n        start_time = time.time()\n        \n        results = []\n        \n        # Process in batches to respect rate limits\n        for i in range(0, len(locations), batch_size):\n            batch = locations[i:i + batch_size]\n            batch_results = []\n            \n            # Process batch concurrently\n            tasks = [\n                self.geocode_location(\n                    location.get('city', ''),\n                    location.get('state', ''),\n                    location.get('country', 'USA')\n                )\n                for location in batch\n            ]\n            \n            batch_results = await asyncio.gather(*tasks, return_exceptions=True)\n            \n            # Handle exceptions\n            for j, result in enumerate(batch_results):\n                if isinstance(result, Exception):\n                    logger.logger.error(f\"Geocoding error for location {i+j}: {result}\")\n                    results.append(None)\n                else:\n                    results.append(result)\n            \n            # Progress callback\n            if progress_callback:\n                progress_callback(min(i + batch_size, len(locations)), len(locations))\n            \n            # Small delay between batches\n            if i + batch_size < len(locations):\n                await asyncio.sleep(1.0)\n        \n        # Save cache after batch processing\n        self.save_cache()\n        \n        processing_time = time.time() - start_time\n        self.stats['processing_time'] = processing_time\n        \n        success_count = sum(1 for r in results if r is not None)\n        logger.logger.info(\n            f\"Batch geocoding completed: {success_count}/{len(locations)} successful \"\n            f\"in {processing_time:.2f} seconds\"\n        )\n        \n        return results\n    \n    def get_records_needing_geocoding(self, limit: int = 1000) -> List[Dict[str, Any]]:\n        \"\"\"Get records from database that need geocoding.\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            conn.row_factory = sqlite3.Row\n            \n            cursor = conn.cursor()\n            cursor.execute(\"\"\"\n                SELECT id, city, state, country, latitude, longitude\n                FROM missing_persons \n                WHERE (latitude IS NULL OR longitude IS NULL)\n                  AND city IS NOT NULL \n                  AND state IS NOT NULL\n                  AND city != ''\n                  AND state != ''\n                LIMIT ?\n            \"\"\", (limit,))\n            \n            records = [dict(row) for row in cursor.fetchall()]\n            conn.close()\n            \n            logger.logger.info(f\"Found {len(records)} records needing geocoding\")\n            return records\n            \n        except Exception as e:\n            logger.logger.error(f\"Error querying records needing geocoding: {e}\")\n            return []\n    \n    def update_record_coordinates(self, record_id: int, lat: float, lon: float, \n                                provider: str = 'unknown') -> bool:\n        \"\"\"Update coordinates for a specific record in the database.\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            cursor.execute(\"\"\"\n                UPDATE missing_persons \n                SET latitude = ?, longitude = ?, geocoding_provider = ?, geocoded_at = ?\n                WHERE id = ?\n            \"\"\", (lat, lon, provider, datetime.now().isoformat(), record_id))\n            \n            conn.commit()\n            conn.close()\n            \n            return cursor.rowcount > 0\n            \n        except Exception as e:\n            logger.logger.error(f\"Error updating coordinates for record {record_id}: {e}\")\n            return False\n    \n    async def process_pending_geocoding(self, limit: int = 500) -> Dict[str, Any]:\n        \"\"\"Automatically process records that need geocoding.\"\"\"\n        logger.logger.info(f\"Starting automatic geocoding process (limit: {limit})\")\n        start_time = time.time()\n        \n        # Get records needing geocoding\n        records = self.get_records_needing_geocoding(limit)\n        if not records:\n            logger.logger.info(\"No records need geocoding\")\n            return {\n                'processed': 0,\n                'successful': 0,\n                'failed': 0,\n                'duration': 0\n            }\n        \n        # Prepare locations for batch geocoding\n        locations = [\n            {\n                'city': record['city'],\n                'state': record['state'],\n                'country': record.get('country', 'USA')\n            }\n            for record in records\n        ]\n        \n        # Progress callback\n        def progress_callback(processed, total):\n            if processed % 50 == 0 or processed == total:\n                logger.logger.info(f\"Geocoding progress: {processed}/{total}\")\n        \n        # Batch geocode\n        results = await self.batch_geocode(locations, progress_callback)\n        \n        # Update database with results\n        successful_updates = 0\n        failed_updates = 0\n        \n        for i, (record, result) in enumerate(zip(records, results)):\n            if result:\n                success = self.update_record_coordinates(\n                    record['id'],\n                    result['lat'],\n                    result['lon'],\n                    result['provider']\n                )\n                if success:\n                    successful_updates += 1\n                else:\n                    failed_updates += 1\n            else:\n                failed_updates += 1\n        \n        duration = time.time() - start_time\n        \n        logger.logger.info(\n            f\"Automatic geocoding completed: {successful_updates} successful, \"\n            f\"{failed_updates} failed in {duration:.2f} seconds\"\n        )\n        \n        return {\n            'processed': len(records),\n            'successful': successful_updates,\n            'failed': failed_updates,\n            'duration': duration,\n            'stats': self.get_stats()\n        }\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get geocoding statistics.\"\"\"\n        total_requests = self.stats['cache_hits'] + self.stats['cache_misses']\n        cache_hit_rate = (self.stats['cache_hits'] / total_requests * 100) if total_requests > 0 else 0\n        \n        return {\n            'cache_entries': len(self.cache),\n            'cache_hit_rate': round(cache_hit_rate, 2),\n            'successful_geocodes': self.stats['successful_geocodes'],\n            'failed_geocodes': self.stats['failed_geocodes'],\n            'provider_usage': self.stats['provider_usage'],\n            'processing_time': self.stats['processing_time']\n        }\n\n# Async wrapper for synchronous usage\ndef run_geocoding_process(config: Dict[str, Any], limit: int = 500) -> Dict[str, Any]:\n    \"\"\"Run the geocoding process synchronously.\"\"\"\n    service = EnhancedGeocodingService(config)\n    \n    async def _run():\n        return await service.process_pending_geocoding(limit)\n    \n    return asyncio.run(_run())\n\ndef main():\n    \"\"\"CLI entry point for enhanced geocoding.\"\"\"\n    import argparse\n    \n    parser = argparse.ArgumentParser(description=\"Enhanced Geocoding Service\")\n    parser.add_argument('--limit', type=int, default=500, help='Maximum records to process')\n    parser.add_argument('--stats', action='store_true', help='Show geocoding statistics')\n    \n    args = parser.parse_args()\n    \n    config = {\n        'cache_file': 'geocache.json',\n        'database_path': 'database/app.db'\n    }\n    \n    if args.stats:\n        service = EnhancedGeocodingService(config)\n        stats = service.get_stats()\n        print(json.dumps(stats, indent=2))\n    else:\n        result = run_geocoding_process(config, args.limit)\n        print(f\"Geocoding completed: {result['successful']}/{result['processed']} successful\")\n\nif __name__ == '__main__':\n    main()