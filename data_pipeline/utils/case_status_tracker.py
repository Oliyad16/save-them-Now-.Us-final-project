"""
Case status tracking and update detection system.
Monitors changes in missing persons cases and tracks status updates.
"""

import sqlite3
import json
import hashlib
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum

from .logger import get_logger

logger = get_logger("case_tracker")

class CaseStatus(Enum):
    """Enumeration of possible case statuses."""
    ACTIVE = "active"
    FOUND_SAFE = "found_safe"
    FOUND_DECEASED = "found_deceased"
    CLOSED = "closed"
    SUSPENDED = "suspended"
    UNDER_INVESTIGATION = "under_investigation"

class CaseChangeType(Enum):
    """Types of changes that can occur to cases."""
    NEW_CASE = "new_case"
    STATUS_CHANGE = "status_change"
    INFORMATION_UPDATE = "information_update"
    LOCATION_UPDATE = "location_update"
    CONTACT_UPDATE = "contact_update"
    DELETION = "deletion"

@dataclass\nclass CaseChange:\n    \"\"\"Represents a change to a missing person case.\"\"\"\n    case_id: str\n    change_type: CaseChangeType\n    old_value: Optional[Dict[str, Any]]\n    new_value: Optional[Dict[str, Any]]\n    timestamp: datetime\n    source: str\n    confidence: float  # 0.0 to 1.0\n    description: str\n\nclass CaseStatusTracker:\n    \"\"\"Tracks and monitors changes in missing persons cases.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.db_path = Path(config.get('database_path', 'database/app.db'))\n        self.changes_db_path = Path(config.get('changes_db_path', 'case_changes.db'))\n        \n        # Initialize changes tracking database\n        self.init_changes_database()\n        \n        # Configuration for change detection\n        self.tracking_config = {\n            'track_status_changes': True,\n            'track_information_updates': True,\n            'track_location_changes': True,\n            'min_confidence_threshold': 0.7,\n            'batch_size': 1000,\n            'retention_days': 365  # Keep change history for 1 year\n        }\n        \n        # Fields that trigger different types of changes\n        self.field_mappings = {\n            'status_fields': ['status', 'case_status', 'investigation_status'],\n            'identity_fields': ['name', 'age', 'gender', 'ethnicity'],\n            'location_fields': ['city', 'state', 'county', 'latitude', 'longitude'],\n            'contact_fields': ['phone', 'email', 'contact_info'],\n            'description_fields': ['description', 'circumstances', 'details']\n        }\n    \n    def init_changes_database(self):\n        \"\"\"Initialize the changes tracking database.\"\"\"\n        try:\n            conn = sqlite3.connect(self.changes_db_path)\n            cursor = conn.cursor()\n            \n            # Create changes table\n            cursor.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS case_changes (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    case_id TEXT NOT NULL,\n                    change_type TEXT NOT NULL,\n                    old_value TEXT,\n                    new_value TEXT,\n                    timestamp TEXT NOT NULL,\n                    source TEXT NOT NULL,\n                    confidence REAL NOT NULL,\n                    description TEXT,\n                    processed BOOLEAN DEFAULT FALSE,\n                    created_at TEXT DEFAULT CURRENT_TIMESTAMP\n                )\n            \"\"\")\n            \n            # Create case snapshots table for comparison\n            cursor.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS case_snapshots (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    case_id TEXT NOT NULL,\n                    snapshot_hash TEXT NOT NULL,\n                    snapshot_data TEXT NOT NULL,\n                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,\n                    UNIQUE(case_id, snapshot_hash)\n                )\n            \"\"\")\n            \n            # Create indexes for performance\n            cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_changes_case_id ON case_changes(case_id)\")\n            cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_changes_timestamp ON case_changes(timestamp)\")\n            cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_changes_type ON case_changes(change_type)\")\n            cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_snapshots_case_id ON case_snapshots(case_id)\")\n            \n            conn.commit()\n            conn.close()\n            \n            logger.logger.info(\"Case changes database initialized\")\n            \n        except Exception as e:\n            logger.logger.error(f\"Failed to initialize changes database: {e}\")\n            raise\n    \n    def calculate_case_hash(self, case_data: Dict[str, Any]) -> str:\n        \"\"\"Calculate a hash of case data for change detection.\"\"\"\n        # Create a normalized version of the case data for hashing\n        normalized_data = {\n            k: str(v).strip().lower() if isinstance(v, str) else v\n            for k, v in case_data.items()\n            if v is not None and k not in ['id', 'created_at', 'updated_at', 'last_checked']\n        }\n        \n        # Sort keys for consistent hashing\n        sorted_data = json.dumps(normalized_data, sort_keys=True)\n        return hashlib.sha256(sorted_data.encode()).hexdigest()\n    \n    def get_current_cases(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all current cases from the main database.\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            conn.row_factory = sqlite3.Row\n            \n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM missing_persons ORDER BY id\")\n            \n            cases = [dict(row) for row in cursor.fetchall()]\n            conn.close()\n            \n            return cases\n            \n        except Exception as e:\n            logger.logger.error(f\"Error getting current cases: {e}\")\n            return []\n    \n    def get_last_snapshot(self, case_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Get the last snapshot of a case for comparison.\"\"\"\n        try:\n            conn = sqlite3.connect(self.changes_db_path)\n            cursor = conn.cursor()\n            \n            cursor.execute(\"\"\"\n                SELECT snapshot_data FROM case_snapshots \n                WHERE case_id = ? \n                ORDER BY created_at DESC \n                LIMIT 1\n            \"\"\", (case_id,))\n            \n            result = cursor.fetchone()\n            conn.close()\n            \n            if result:\n                return json.loads(result[0])\n            return None\n            \n        except Exception as e:\n            logger.logger.error(f\"Error getting last snapshot for case {case_id}: {e}\")\n            return None\n    \n    def save_case_snapshot(self, case_id: str, case_data: Dict[str, Any]) -> bool:\n        \"\"\"Save a snapshot of case data.\"\"\"\n        try:\n            case_hash = self.calculate_case_hash(case_data)\n            snapshot_data = json.dumps(case_data, default=str)\n            \n            conn = sqlite3.connect(self.changes_db_path)\n            cursor = conn.cursor()\n            \n            cursor.execute(\"\"\"\n                INSERT OR IGNORE INTO case_snapshots \n                (case_id, snapshot_hash, snapshot_data) \n                VALUES (?, ?, ?)\n            \"\"\", (case_id, case_hash, snapshot_data))\n            \n            conn.commit()\n            conn.close()\n            \n            return True\n            \n        except Exception as e:\n            logger.logger.error(f\"Error saving snapshot for case {case_id}: {e}\")\n            return False\n    \n    def detect_case_changes(self, current_case: Dict[str, Any], \n                          previous_case: Optional[Dict[str, Any]]) -> List[CaseChange]:\n        \"\"\"Detect changes between current and previous case data.\"\"\"\n        changes = []\n        case_id = str(current_case.get('id', current_case.get('case_number', 'unknown')))\n        \n        if previous_case is None:\n            # New case\n            changes.append(CaseChange(\n                case_id=case_id,\n                change_type=CaseChangeType.NEW_CASE,\n                old_value=None,\n                new_value=current_case,\n                timestamp=datetime.now(),\n                source='case_tracker',\n                confidence=1.0,\n                description=f\"New missing person case: {current_case.get('name', 'Unknown')}\"\n            ))\n            return changes\n        \n        # Compare each field for changes\n        for field, current_value in current_case.items():\n            if field in ['updated_at', 'last_checked', 'created_at']:\n                continue  # Skip timestamp fields\n            \n            previous_value = previous_case.get(field)\n            \n            # Normalize values for comparison\n            current_normalized = self.normalize_value(current_value)\n            previous_normalized = self.normalize_value(previous_value)\n            \n            if current_normalized != previous_normalized:\n                change_type = self.determine_change_type(field)\n                confidence = self.calculate_change_confidence(field, previous_value, current_value)\n                \n                if confidence >= self.tracking_config['min_confidence_threshold']:\n                    changes.append(CaseChange(\n                        case_id=case_id,\n                        change_type=change_type,\n                        old_value={field: previous_value},\n                        new_value={field: current_value},\n                        timestamp=datetime.now(),\n                        source='case_tracker',\n                        confidence=confidence,\n                        description=f\"{field} changed from '{previous_value}' to '{current_value}'\"\n                    ))\n        \n        return changes\n    \n    def normalize_value(self, value: Any) -> Any:\n        \"\"\"Normalize a value for comparison.\"\"\"\n        if value is None:\n            return None\n        if isinstance(value, str):\n            return value.strip().lower()\n        return value\n    \n    def determine_change_type(self, field_name: str) -> CaseChangeType:\n        \"\"\"Determine the type of change based on the field that changed.\"\"\"\n        field_name_lower = field_name.lower()\n        \n        if any(status_field in field_name_lower for status_field in self.field_mappings['status_fields']):\n            return CaseChangeType.STATUS_CHANGE\n        elif any(loc_field in field_name_lower for loc_field in self.field_mappings['location_fields']):\n            return CaseChangeType.LOCATION_UPDATE\n        elif any(contact_field in field_name_lower for contact_field in self.field_mappings['contact_fields']):\n            return CaseChangeType.CONTACT_UPDATE\n        else:\n            return CaseChangeType.INFORMATION_UPDATE\n    \n    def calculate_change_confidence(self, field_name: str, old_value: Any, new_value: Any) -> float:\n        \"\"\"Calculate confidence level for a detected change.\"\"\"\n        # High confidence for status changes\n        if any(status_field in field_name.lower() for status_field in self.field_mappings['status_fields']):\n            return 0.95\n        \n        # High confidence for coordinate changes (numeric)\n        if field_name.lower() in ['latitude', 'longitude'] and isinstance(new_value, (int, float)):\n            return 0.9\n        \n        # Medium confidence for text changes\n        if isinstance(old_value, str) and isinstance(new_value, str):\n            # Lower confidence if values are very similar\n            similarity = self.calculate_string_similarity(old_value, new_value)\n            return max(0.6, 1.0 - similarity)\n        \n        # Default confidence\n        return 0.8\n    \n    def calculate_string_similarity(self, str1: str, str2: str) -> float:\n        \"\"\"Calculate similarity between two strings (0.0 = identical, 1.0 = completely different).\"\"\"\n        if not str1 and not str2:\n            return 0.0\n        if not str1 or not str2:\n            return 1.0\n        \n        # Simple Levenshtein distance ratio\n        from difflib import SequenceMatcher\n        return 1.0 - SequenceMatcher(None, str1.lower(), str2.lower()).ratio()\n    \n    def record_change(self, change: CaseChange) -> bool:\n        \"\"\"Record a change in the changes database.\"\"\"\n        try:\n            conn = sqlite3.connect(self.changes_db_path)\n            cursor = conn.cursor()\n            \n            cursor.execute(\"\"\"\n                INSERT INTO case_changes \n                (case_id, change_type, old_value, new_value, timestamp, source, confidence, description)\n                VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n            \"\"\", (\n                change.case_id,\n                change.change_type.value,\n                json.dumps(change.old_value, default=str) if change.old_value else None,\n                json.dumps(change.new_value, default=str) if change.new_value else None,\n                change.timestamp.isoformat(),\n                change.source,\n                change.confidence,\n                change.description\n            ))\n            \n            conn.commit()\n            conn.close()\n            \n            return True\n            \n        except Exception as e:\n            logger.logger.error(f\"Error recording change: {e}\")\n            return False\n    \n    def process_case_updates(self) -> Dict[str, Any]:\n        \"\"\"Process all current cases and detect changes.\"\"\"\n        logger.logger.info(\"Starting case update detection\")\n        start_time = datetime.now()\n        \n        stats = {\n            'cases_processed': 0,\n            'changes_detected': 0,\n            'new_cases': 0,\n            'status_changes': 0,\n            'information_updates': 0,\n            'location_updates': 0,\n            'processing_time': 0\n        }\n        \n        try:\n            current_cases = self.get_current_cases()\n            \n            for case in current_cases:\n                case_id = str(case.get('id', case.get('case_number', 'unknown')))\n                \n                # Get previous snapshot\n                previous_case = self.get_last_snapshot(case_id)\n                \n                # Detect changes\n                changes = self.detect_case_changes(case, previous_case)\n                \n                # Record changes\n                for change in changes:\n                    if self.record_change(change):\n                        stats['changes_detected'] += 1\n                        \n                        # Update specific counters\n                        if change.change_type == CaseChangeType.NEW_CASE:\n                            stats['new_cases'] += 1\n                        elif change.change_type == CaseChangeType.STATUS_CHANGE:\n                            stats['status_changes'] += 1\n                        elif change.change_type == CaseChangeType.LOCATION_UPDATE:\n                            stats['location_updates'] += 1\n                        else:\n                            stats['information_updates'] += 1\n                        \n                        logger.logger.info(f\"Change detected: {change.description}\")\n                \n                # Save current snapshot\n                self.save_case_snapshot(case_id, case)\n                stats['cases_processed'] += 1\n                \n                # Progress logging\n                if stats['cases_processed'] % 100 == 0:\n                    logger.logger.info(f\"Processed {stats['cases_processed']} cases\")\n            \n            # Clean up old changes\n            self.cleanup_old_changes()\n            \n            stats['processing_time'] = (datetime.now() - start_time).total_seconds()\n            \n            logger.logger.info(\n                f\"Case update detection completed: {stats['changes_detected']} changes \"\n                f\"detected in {stats['cases_processed']} cases\"\n            )\n            \n            return stats\n            \n        except Exception as e:\n            logger.logger.error(f\"Error processing case updates: {e}\")\n            stats['processing_time'] = (datetime.now() - start_time).total_seconds()\n            stats['error'] = str(e)\n            return stats\n    \n    def cleanup_old_changes(self):\n        \"\"\"Clean up old change records beyond retention period.\"\"\"\n        try:\n            cutoff_date = datetime.now() - timedelta(days=self.tracking_config['retention_days'])\n            \n            conn = sqlite3.connect(self.changes_db_path)\n            cursor = conn.cursor()\n            \n            cursor.execute(\"\"\"\n                DELETE FROM case_changes \n                WHERE timestamp < ?\n            \"\"\", (cutoff_date.isoformat(),))\n            \n            deleted_count = cursor.rowcount\n            \n            # Also clean up old snapshots (keep only latest 5 per case)\n            cursor.execute(\"\"\"\n                DELETE FROM case_snapshots \n                WHERE id NOT IN (\n                    SELECT id FROM (\n                        SELECT id, ROW_NUMBER() OVER (PARTITION BY case_id ORDER BY created_at DESC) as rn\n                        FROM case_snapshots\n                    ) ranked WHERE rn <= 5\n                )\n            \"\"\")\n            \n            conn.commit()\n            conn.close()\n            \n            if deleted_count > 0:\n                logger.logger.info(f\"Cleaned up {deleted_count} old change records\")\n            \n        except Exception as e:\n            logger.logger.error(f\"Error cleaning up old changes: {e}\")\n    \n    def get_recent_changes(self, hours: int = 24, change_types: Optional[List[str]] = None) -> List[Dict[str, Any]]:\n        \"\"\"Get recent changes within the specified time period.\"\"\"\n        try:\n            since_time = datetime.now() - timedelta(hours=hours)\n            \n            conn = sqlite3.connect(self.changes_db_path)\n            conn.row_factory = sqlite3.Row\n            \n            query = \"\"\"\n                SELECT * FROM case_changes \n                WHERE timestamp >= ?\n            \"\"\"\n            params = [since_time.isoformat()]\n            \n            if change_types:\n                placeholders = ','.join('?' * len(change_types))\n                query += f\" AND change_type IN ({placeholders})\"\n                params.extend(change_types)\n            \n            query += \" ORDER BY timestamp DESC\"\n            \n            cursor = conn.cursor()\n            cursor.execute(query, params)\n            \n            changes = [dict(row) for row in cursor.fetchall()]\n            conn.close()\n            \n            return changes\n            \n        except Exception as e:\n            logger.logger.error(f\"Error getting recent changes: {e}\")\n            return []\n    \n    def get_case_history(self, case_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get the complete change history for a specific case.\"\"\"\n        try:\n            conn = sqlite3.connect(self.changes_db_path)\n            conn.row_factory = sqlite3.Row\n            \n            cursor = conn.cursor()\n            cursor.execute(\"\"\"\n                SELECT * FROM case_changes \n                WHERE case_id = ? \n                ORDER BY timestamp DESC\n            \"\"\", (case_id,))\n            \n            history = [dict(row) for row in cursor.fetchall()]\n            conn.close()\n            \n            return history\n            \n        except Exception as e:\n            logger.logger.error(f\"Error getting case history for {case_id}: {e}\")\n            return []\n    \n    def get_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get statistics about case changes and tracking.\"\"\"\n        try:\n            conn = sqlite3.connect(self.changes_db_path)\n            cursor = conn.cursor()\n            \n            # Total changes\n            cursor.execute(\"SELECT COUNT(*) FROM case_changes\")\n            total_changes = cursor.fetchone()[0]\n            \n            # Changes by type\n            cursor.execute(\"\"\"\n                SELECT change_type, COUNT(*) as count \n                FROM case_changes \n                GROUP BY change_type\n            \"\"\")\n            changes_by_type = dict(cursor.fetchall())\n            \n            # Recent changes (last 24 hours)\n            since_24h = (datetime.now() - timedelta(hours=24)).isoformat()\n            cursor.execute(\"\"\"\n                SELECT COUNT(*) FROM case_changes \n                WHERE timestamp >= ?\n            \"\"\", (since_24h,))\n            recent_changes = cursor.fetchone()[0]\n            \n            # Active cases being tracked\n            cursor.execute(\"SELECT COUNT(DISTINCT case_id) FROM case_snapshots\")\n            tracked_cases = cursor.fetchone()[0]\n            \n            conn.close()\n            \n            return {\n                'total_changes': total_changes,\n                'changes_by_type': changes_by_type,\n                'recent_changes_24h': recent_changes,\n                'tracked_cases': tracked_cases,\n                'tracking_config': self.tracking_config\n            }\n            \n        except Exception as e:\n            logger.logger.error(f\"Error getting statistics: {e}\")\n            return {}\n\ndef main():\n    \"\"\"CLI entry point for case status tracking.\"\"\"\n    import argparse\n    \n    parser = argparse.ArgumentParser(description=\"Case Status Tracker\")\n    parser.add_argument('--config', help='Configuration file path')\n    parser.add_argument('--process', action='store_true', help='Process case updates')\n    parser.add_argument('--stats', action='store_true', help='Show tracking statistics')\n    parser.add_argument('--recent', type=int, help='Show recent changes (hours)')\n    \n    args = parser.parse_args()\n    \n    config = {\n        'database_path': 'database/app.db',\n        'changes_db_path': 'case_changes.db'\n    }\n    \n    tracker = CaseStatusTracker(config)\n    \n    if args.process:\n        result = tracker.process_case_updates()\n        print(f\"Processing completed: {result}\")\n    elif args.stats:\n        stats = tracker.get_statistics()\n        print(json.dumps(stats, indent=2))\n    elif args.recent:\n        changes = tracker.get_recent_changes(hours=args.recent)\n        print(f\"Recent changes ({args.recent} hours):\")\n        for change in changes:\n            print(f\"  {change['timestamp']}: {change['description']}\")\n    else:\n        parser.print_help()\n\nif __name__ == '__main__':\n    main()